{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a GRU model using Trax: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will be using Trax's layers to implement the GRU architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q -U trax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment to install trax \n",
    "#%pip install trax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'trax'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\skand\\Documents\\GitHub\\deeplearning.ai\\4 Natural Language Processing\\3 NLP with Sequence Models\\2 recurrent neurals networks for language modeling\\4 creatinig GRU with trax\\GRU_model_with_trax.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/skand/Documents/GitHub/deeplearning.ai/4%20Natural%20Language%20Processing/3%20NLP%20with%20Sequence%20Models/2%20recurrent%20neurals%20networks%20for%20language%20modeling/4%20creatinig%20GRU%20with%20trax/GRU_model_with_trax.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtrax\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/skand/Documents/GitHub/deeplearning.ai/4%20Natural%20Language%20Processing/3%20NLP%20with%20Sequence%20Models/2%20recurrent%20neurals%20networks%20for%20language%20modeling/4%20creatinig%20GRU%20with%20trax/GRU_model_with_trax.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtrax\u001b[39;00m \u001b[39mimport\u001b[39;00m layers \u001b[39mas\u001b[39;00m tl\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/skand/Documents/GitHub/deeplearning.ai/4%20Natural%20Language%20Processing/3%20NLP%20with%20Sequence%20Models/2%20recurrent%20neurals%20networks%20for%20language%20modeling/4%20creatinig%20GRU%20with%20trax/GRU_model_with_trax.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# A helper function that prints information for every layer (sublayer within `Serial`):\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'trax'"
     ]
    }
   ],
   "source": [
    "import trax\n",
    "from trax import layers as tl\n",
    "\n",
    "# A helper function that prints information for every layer (sublayer within `Serial`):\n",
    "from utils import show_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trax allows us to define neural network architectures by stacking layers (similarly to other libraries such as Keras). For this the `Serial()` which is the Keras's Sequential \"equivalent\" is often used as it is a combinator that allows to stack layers serially using function composition.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a `GRU` model we will need the following Trax layers (Documentation link attached with each layer name):\n",
    "   - [`ShiftRight`](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.attention.ShiftRight) Shifts the tensor to the right by padding with zeros on axis 1. The `mode` should be specified and it refers to the context in which the model is being used. Possible values are: 'train', 'eval' or 'predict', predict mode is for fast inference. Defaults to \"train\". With this layer, the input sequence is shifted to the right so, at every time step, the GRU cell doesn't get as input the same element that needs to be predicted. Note that this layer isn't always neccessary, its inclusion depends on the NLP task at hand.\n",
    "\n",
    "   - [`Embedding`](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Embedding) Maps discrete tokens to vectors. It will have shape `(vocabulary length X dimension of output vectors)`. The dimension of output vectors (also called `d_feature`) is the number of elements in the word embedding.\n",
    "   - [`GRU`](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.rnn.GRU) The GRU layer. It leverages another Trax layer called [`GRUCell`](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.rnn.GRUCell). The hidden state dimension should be specified as `n_units` and should match the number of elements in the word embedding --by design in Trax. If we want to stack two consecutive GRU layers, it can be done by using python's list comprehension. to get the following architecture\n",
    "\n",
    "   <img src=\"images/3_grus.png\" width=\"400\"/>\n",
    "\n",
    "   - [`Dense`](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Dense) Vanilla Dense layer.\n",
    "   - [`LogSoftMax`](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.LogSoftmax) Log Softmax function.\n",
    "\n",
    "Putting everything together the GRU model will look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'train'\n",
    "vocab_size = 256\n",
    "model_dimension = 512\n",
    "n_layers = 3\n",
    "\n",
    "GRU = tl.Serial(\n",
    "      # Do remember to pass the mode parameter if you are using it for interence/test \n",
    "      # as default is train \n",
    "      tl.ShiftRight(mode=mode), \n",
    "      tl.Embedding(vocab_size=vocab_size, d_feature=model_dimension),\n",
    "      # Stack 3 GRU layers together\n",
    "      [tl.GRU(n_units=model_dimension) for _ in range(n_layers)], \n",
    "      tl.Dense(n_units=vocab_size),\n",
    "      tl.LogSoftmax()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_layers(GRU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! a full GRU architecture with 5 lines using Trax !!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
